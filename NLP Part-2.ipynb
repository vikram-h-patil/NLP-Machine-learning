{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this second part of NLP, Random Forest model is applied to the data to predict the mails from spam and non-spam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Machine Learning Classifiers: Building a basic Random Forest model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in & clean text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body_len</th>\n",
       "      <th>punct%</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>...</th>\n",
       "      <th>8094</th>\n",
       "      <th>8095</th>\n",
       "      <th>8096</th>\n",
       "      <th>8097</th>\n",
       "      <th>8098</th>\n",
       "      <th>8099</th>\n",
       "      <th>8100</th>\n",
       "      <th>8101</th>\n",
       "      <th>8102</th>\n",
       "      <th>8103</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>3.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>7.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>135</td>\n",
       "      <td>4.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 8106 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   body_len  punct%    0    1    2    3    4    5    6    7  ...   8094  8095  \\\n",
       "0       128     4.7  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "1        49     4.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "2        62     3.2  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "3        28     7.1  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "4       135     4.4  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   0.0   \n",
       "\n",
       "   8096  8097  8098  8099  8100  8101  8102  8103  \n",
       "0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "1   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "2   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "3   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "4   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 8106 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import string\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "ps = nltk.PorterStemmer()\n",
    "\n",
    "data = pd.read_csv(\"SMSSpamCollection.tsv\", sep='\\t')\n",
    "data.columns = ['label', 'body_text']\n",
    "\n",
    "def count_punct(text):\n",
    "    count = sum([1 for char in text if char in string.punctuation])\n",
    "    return round(count/(len(text) - text.count(\" \")), 3)*100\n",
    "\n",
    "data['body_len'] = data['body_text'].apply(lambda x: len(x) - x.count(\" \"))\n",
    "data['punct%'] = data['body_text'].apply(lambda x: count_punct(x))\n",
    "\n",
    "def clean_text(text):\n",
    "    text = \"\".join([word.lower() for word in text if word not in string.punctuation])\n",
    "    tokens = re.split('\\W+', text)\n",
    "    text = [ps.stem(word) for word in tokens if word not in stopwords]\n",
    "    return text\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer=clean_text)\n",
    "X_tfidf = tfidf_vect.fit_transform(data['body_text'])\n",
    "\n",
    "X_features = pd.concat([data['body_len'], data['punct%'], pd.DataFrame(X_tfidf.toarray())], axis=1)\n",
    "X_features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " --------------------------------------------------------------------------------------\n",
    " ### RandomForest Classifier through Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(X_features,data['label'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=50, max_depth=20,n_jobs=-1)\n",
    "\n",
    "rf_model=rf.fit(x_train,y_train) #stores a fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.061342193118805566, 'body_len'),\n",
       " (0.04430376899285169, 1803),\n",
       " (0.028392492108139555, 2031),\n",
       " (0.020566587759555239, 7461),\n",
       " (0.020562640305861891, 7350),\n",
       " (0.020444607517757004, 7027),\n",
       " (0.018310760130820742, 3134),\n",
       " (0.017597806511971164, 4796),\n",
       " (0.015907402896787479, 6285),\n",
       " (0.015797520692157275, 5078)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(zip(rf_model.feature_importances_,x_train.columns),reverse=True)[0:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### body len is most imnportant feature, also confirmed through feature evaluation \n",
    "\n",
    "------------------\n",
    "\n",
    "### Predict phase from fit model. Here I am predicting on x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred=rf_model.predict(x_test)\n",
    "\n",
    "# Performance metrics\n",
    "# positive label = What we are interested to predicting. We care about Spam\n",
    "\n",
    "precision,recall,fscore,support=score(y_test,y_pred,pos_label='spam',average='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision:100.0 / Recall:60.274 / Accuracy:94.794\n"
     ]
    }
   ],
   "source": [
    "print('Precision:{} / Recall:{} / Accuracy:{}'.format(round(precision*100,3),\n",
    "                                                     round(recall*100,3),\n",
    "                                            round((y_pred==y_test).sum()/len(y_pred)*100,3)))\n",
    "\n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary:\n",
    "\n",
    "* body len is most imnportant feature, also confirmed through feature evaluation \n",
    "* Based on 100% precision, we can confirm that all mail in the spam folder is actually spam.\n",
    "\n",
    "* And with 94% accuracy, mails which have come to email were identified as spam or ham\n",
    "\n",
    "* Only 60% recall, suggests that 60% of all spam that has come into email was properly placed in spam folder."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "### Grid-search\n",
    "\n",
    "Why grid serach?\n",
    "\n",
    "\n",
    "In last section, we fit a single model with a single set of hyperparameter settings and then we generated a single set of evaluation metrics.\n",
    "\n",
    "We can imporve our model by changing the hyperparameter settings, like the max depth or estimators\n",
    "\n",
    "Could be capture more spam by altering hyperparameter setting?, thats when grid search comes in. Grid search basically means defining a grid of hyperparameter settings, and then exploring a model fit with each combination of those hyperparameter settings.\n",
    "\n",
    "So in our case, that means setting a range of number of estimators and a range of max depth, that you'd like to explore. And then grid search will test every combination of those and fit a model and evaluate it to see which hyperparameter combination generates the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " x_train,x_test,y_train,y_test=train_test_split(X_features,data['label'],test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_RF(n_est,depth):\n",
    "    rf=RandomForestClassifier(n_estimators=n_est,max_depth=depth,n_jobs=-1)\n",
    "    rf_model=rf.fit(x_train,y_train)\n",
    "    y_pred=rf_model.predict(x_test)\n",
    "    \n",
    "    precision,recall,fscore,support=score(y_test,y_pred,pos_label='spam',average='binary')\n",
    "    \n",
    "    print(\"Est:{} / Depth:{} -------- Precision: {}% / Recall:{}% / Accuracy: {}%\".format\n",
    "          (n_est,depth,round(precision*100,3),round(recall*100, 3),round((y_pred==y_test).sum()/len(y_pred)*100,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Est:10 / Depth:10 -------- Precision: 100.0% / Recall:20.144% / Accuracy: 90.036%\n",
      "Est:10 / Depth:20 -------- Precision: 100.0% / Recall:48.201% / Accuracy: 93.537%\n",
      "Est:10 / Depth:30 -------- Precision: 99.01% / Recall:71.942% / Accuracy: 96.409%\n",
      "Est:10 / Depth:None -------- Precision: 99.091% / Recall:78.417% / Accuracy: 97.217%\n",
      "Est:50 / Depth:10 -------- Precision: 100.0% / Recall:25.899% / Accuracy: 90.754%\n",
      "Est:50 / Depth:20 -------- Precision: 100.0% / Recall:53.237% / Accuracy: 94.165%\n",
      "Est:50 / Depth:30 -------- Precision: 100.0% / Recall:69.065% / Accuracy: 96.14%\n",
      "Est:50 / Depth:None -------- Precision: 100.0% / Recall:80.576% / Accuracy: 97.576%\n",
      "Est:100 / Depth:10 -------- Precision: 100.0% / Recall:28.058% / Accuracy: 91.023%\n",
      "Est:100 / Depth:20 -------- Precision: 100.0% / Recall:54.676% / Accuracy: 94.345%\n",
      "Est:100 / Depth:30 -------- Precision: 100.0% / Recall:68.345% / Accuracy: 96.05%\n",
      "Est:100 / Depth:None -------- Precision: 100.0% / Recall:80.576% / Accuracy: 97.576%\n"
     ]
    }
   ],
   "source": [
    "for n_est in [10,50,100]:\n",
    "    for depth in[10,20,30,None]:\n",
    "        train_RF(n_est,depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "* Hence when tuning depth reached 30, we are getting good result. Thus, max depth to be taken into consideration.\n",
    "* body len is most imnportant feature, also confirmed through feature evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
